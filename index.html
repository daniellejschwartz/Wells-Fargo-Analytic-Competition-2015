<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Wells Fargo Analytics Competition 2015 by daniellejschwartz</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Wells Fargo Analytics Competition 2015</h1>
      <h2 class="project-tagline">An interpretation of social media posts to determine bank qualities</h2>
      <a href="https://github.com/daniellejschwartz/Wells-Fargo-Analytic-Competition-2015" class="btn">View on GitHub</a>
      <a href="https://github.com/daniellejschwartz/Wells-Fargo-Analytic-Competition-2015/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/daniellejschwartz/Wells-Fargo-Analytic-Competition-2015/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="competition-overview" class="anchor" href="#competition-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Competition Overview</h1>

<p>The Wells Fargo Analytic Competition asked groups from Colleges and Universities to analyze a data set of Twitter and Facebook posts in order to develop solutions to the following questions:
<strong>What financial and bank topics* are consumers discussing in social media and what caused the consumers to post online about these topics?
Are the topics and “substance” consistent across the industry or are they isolated to individual banks?</strong></p>

<p>Here are a few sample posts from the original data set received from Wells Fargo:</p>

<div class="highlight highlight-source-r"><pre><span class="pl-c1">118</span><span class="pl-k">|</span><span class="pl-c1">11</span><span class="pl-k">/</span><span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">2014</span><span class="pl-k">|</span><span class="pl-c1">2014</span><span class="pl-k">|</span><span class="pl-c1">11</span><span class="pl-k">|</span><span class="pl-smi">facebook</span><span class="pl-k">|</span><span class="pl-k">-</span> <span class="pl-smi">Name</span> <span class="pl-smi">had</span> <span class="pl-smi">BankB</span> <span class="pl-k">for</span> <span class="pl-smi">over</span> <span class="pl-c1">8</span> <span class="pl-smi">years</span> <span class="pl-smi">years</span> 
    <span class="pl-smi">and</span> <span class="pl-smi">no</span> <span class="pl-smi">complaints</span> <span class="pl-smi">at</span> <span class="pl-smi">all</span><span class="pl-k">!</span> <span class="pl-smi">absolutely</span> <span class="pl-smi">love</span> <span class="pl-smi">BankB</span><span class="pl-k">!</span>
<span class="pl-c1">123</span><span class="pl-k">|</span><span class="pl-c1">8</span><span class="pl-k">/</span><span class="pl-c1">27</span><span class="pl-k">/</span><span class="pl-c1">2015</span><span class="pl-k">|</span><span class="pl-c1">2015</span><span class="pl-k">|</span><span class="pl-c1">8</span><span class="pl-k">|</span><span class="pl-smi">twitter</span><span class="pl-k">|</span><span class="pl-k">-</span> <span class="pl-smi">Name</span> <span class="pl-smi">bouta</span> <span class="pl-smi">get</span> <span class="pl-smi">a</span> <span class="pl-smi">banke</span> <span class="pl-smi">account</span>. <span class="pl-smi">BankB</span>
    <span class="pl-smi">got</span> <span class="pl-smi">too</span> <span class="pl-smi">many</span> <span class="pl-smi">fees</span> <span class="pl-k">for</span> <span class="pl-smi">Name</span>.
<span class="pl-c1">140</span><span class="pl-k">|</span><span class="pl-c1">8</span><span class="pl-k">/</span><span class="pl-c1">18</span><span class="pl-k">/</span><span class="pl-c1">2014</span><span class="pl-k">|</span><span class="pl-c1">2014</span><span class="pl-k">|</span><span class="pl-c1">8</span><span class="pl-k">|</span><span class="pl-smi">facebook</span><span class="pl-k">|</span><span class="pl-k">:</span>(<span class="pl-smi">oh</span> <span class="pl-smi">BankA</span>.. <span class="pl-smi">every</span> <span class="pl-smi">single</span> <span class="pl-smi">time</span> <span class="pl-smi">i</span> <span class="pl-smi">do</span> 
    <span class="pl-smi">something</span> <span class="pl-smi">on</span> <span class="pl-smi">accident</span> <span class="pl-smi">it</span> <span class="pl-smi">takes</span> <span class="pl-c1">5</span><span class="pl-k">-</span><span class="pl-c1">10</span> <span class="pl-smi">business</span> <span class="pl-smi">days</span> <span class="pl-smi">to</span> <span class="pl-smi">reverse</span><span class="pl-k">!</span><span class="pl-k">...</span>
    <span class="pl-smi">why</span> <span class="pl-smi">cant</span> <span class="pl-smi">i</span> <span class="pl-smi">leave</span> <span class="pl-smi">you</span>?<span class="pl-k">!</span>.. <span class="pl-smi">why</span> <span class="pl-smi">cant</span> <span class="pl-smi">i</span> <span class="pl-smi">just</span> <span class="pl-smi">go</span> <span class="pl-smi">to</span> <span class="pl-smi">a</span> <span class="pl-smi">banke</span><span class="pl-k">...</span>
<span class="pl-c1">186</span><span class="pl-k">|</span><span class="pl-c1">8</span><span class="pl-k">/</span><span class="pl-c1">21</span><span class="pl-k">/</span><span class="pl-c1">2015</span><span class="pl-k">|</span><span class="pl-c1">2015</span><span class="pl-k">|</span><span class="pl-c1">8</span><span class="pl-k">|</span><span class="pl-smi">twitter</span><span class="pl-k">|</span><span class="pl-smi">mannn</span> <span class="pl-k">*</span> <span class="pl-smi">checks</span> <span class="pl-smi">BankD</span> <span class="pl-smi">account</span> <span class="pl-k">*</span> <span class="pl-smi">INTERNET</span> Ö</pre></div>

<h1>
<a id="our-approach" class="anchor" href="#our-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Our Approach</h1>

<p>The following procedure was developed to analyze the given data for posts specific to BankA, BankB, BankC, and BankD using the R programming language:</p>

<p><img src="http://i.imgur.com/YYxuhly.jpg" alt=""></p>

<h3>
<a id="upload-packages" class="anchor" href="#upload-packages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Upload Packages</h3>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#Install Required Packages</span>
<span class="pl-smi">needed</span> <span class="pl-k">&lt;-</span> c(<span class="pl-s"><span class="pl-pds">"</span>tm<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>SnowballC<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>RColorBrewer<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>ggplot2<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>wordcloud<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>biclust<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>cluster<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>igraph<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>fpc<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>slam<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>plyr<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>doMC<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>stringr<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>randomForest<span class="pl-pds">"</span></span>)
<span class="pl-c">#install.packages(needed, dependencies=TRUE) #This only needs to be done once</span>
<span class="pl-v">list</span> <span class="pl-k">=</span> lapply(<span class="pl-smi">needed</span>, <span class="pl-smi">require</span>, <span class="pl-v">character.only</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>) <span class="pl-c">#This needs to be done every time you restart R</span></pre></div>

<h3>
<a id="cleaning-the-data" class="anchor" href="#cleaning-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaning the Data</h3>

<p>After uploading the original data set into R and uploading the necessary packages (see above), the data was cleaned using the following methodology in order to create a data set that would be easier to work with and extract valuable information from. </p>

<p><strong>1) Remove metadata</strong>
![Click to view metadata](<a href="http://i.imgur.com/A9KroLz.png">http://i.imgur.com/A9KroLz.png</a></p>

<p><strong>2) Remove non-ASCII characters</strong></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#This function removes the non-ASCII characters from the text so that it can be analyzed </span>
<span class="pl-v">removeOffendingCharacters</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">df</span>)
{
  <span class="pl-v">df.texts.clean</span> <span class="pl-k">=</span> as.data.frame(iconv(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-s"><span class="pl-pds">"</span>latin1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>ASCII<span class="pl-pds">"</span></span>, <span class="pl-v">sub</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>))
  colnames(<span class="pl-smi">df.texts.clean</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> <span class="pl-smi">df.texts.clean</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>
  <span class="pl-k">return</span>(<span class="pl-smi">df</span>)
}</pre></div>

<p><strong>3) Create function to remove white space, punctuation, numbers, stop words, change to lowercase</strong></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#This function performs several operations to clean up the text, including:</span>
<span class="pl-c">#Removing extra whitespace</span>
<span class="pl-c">#Removing any punctuation with the exception of '_'</span>
<span class="pl-c">#Removing numbers</span>
<span class="pl-c">#Converting all text to lowercase</span>
<span class="pl-c">#Removing common and meaningless words (stopwords)</span>
<span class="pl-v">cleanText</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">df</span>)
{
  require(<span class="pl-smi">tm</span>)
  <span class="pl-v">docs</span> <span class="pl-k">=</span> Corpus(VectorSource(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>))
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stripWhitespace</span>)
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-s"><span class="pl-pds">"</span>english<span class="pl-pds">"</span></span>))  
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeNumbers</span>)   
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">tolower</span>) 
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)
  <span class="pl-v">removeSomePunct</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">x</span>) gsub(<span class="pl-s"><span class="pl-pds">"</span>[^[:alnum:][:blank:]_]<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, <span class="pl-smi">x</span>)
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, content_transformer(<span class="pl-smi">removeSomePunct</span>))
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stripWhitespace</span>)  
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)

  <span class="pl-v">df.texts.cleaner</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">docs</span>, `[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">F</span>)
  colnames(<span class="pl-smi">df.texts.cleaner</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullTextClean</span> <span class="pl-k">=</span> <span class="pl-smi">df.texts.cleaner</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>
  <span class="pl-k">return</span>(<span class="pl-smi">df</span>)
}</pre></div>

<p><strong>4) Remove stems</strong></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#This function "stemms" the document, meaning that it removes word endings like "ing", "ed", and "es"</span>
<span class="pl-c">#For example, it will change the words "analyze", "analyzing", and "analyzed" to "analyz" </span>
<span class="pl-c">#This makes it so that they are all treated as the same word</span>
<span class="pl-v">stemText</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">df</span>)
{
  require(<span class="pl-smi">tm</span>)
  require(<span class="pl-smi">SnowballC</span>)
  <span class="pl-v">docs</span> <span class="pl-k">=</span> Corpus(VectorSource(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullTextClean</span>))
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stemDocument</span>)
  <span class="pl-v">docs</span> <span class="pl-k">=</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)
  <span class="pl-v">df.texts.cleaner</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">docs</span>, `[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">F</span>)
  colnames(<span class="pl-smi">df.texts.cleaner</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullTextStemmed</span> <span class="pl-k">=</span> <span class="pl-smi">df.texts.cleaner</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>
  <span class="pl-k">return</span>(<span class="pl-smi">df</span>)
}</pre></div>

<h3>
<a id="exploratory-data-analysis" class="anchor" href="#exploratory-data-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploratory Data Analysis</h3>

<p>We began our analysis by exploring the data, examining common word frequencies, and identifying clusters of words. These preliminary results helped direct us in our classification and sentiment analyses.</p>

<p><strong>Analysis of frequent words</strong></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#Create a Document Term Matrix to analyze the texts</span>
<span class="pl-v">docs</span> <span class="pl-k">=</span> Corpus(VectorSource(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullTextClean</span>))
<span class="pl-v">dtm</span> <span class="pl-k">=</span> DocumentTermMatrix(<span class="pl-smi">docs</span>)   
<span class="pl-v">dtm.sparse</span> <span class="pl-k">=</span> <span class="pl-smi">dtms</span> <span class="pl-k">&lt;-</span> removeSparseTerms(<span class="pl-smi">dtm</span>, <span class="pl-c1">0.999</span>)
<span class="pl-v">dtm.sparse.simple</span> <span class="pl-k">=</span> as.simple_triplet_matrix(<span class="pl-smi">dtm.sparse</span>) 

<span class="pl-c">#Compute the word frequencies</span>
<span class="pl-smi">freq</span> <span class="pl-k">&lt;-</span> sort(col_sums(<span class="pl-smi">dtm.sparse.simple</span>), <span class="pl-v">decreasing</span><span class="pl-k">=</span><span class="pl-c1">TRUE</span>)   
<span class="pl-c">#Remove the 9 most frequently occuring words because they are outliers</span>
<span class="pl-v">freq</span> <span class="pl-k">=</span> <span class="pl-smi">freq</span>[<span class="pl-k">-</span>c(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">9</span>)]
<span class="pl-smi">wf</span> <span class="pl-k">&lt;-</span> <span class="pl-k">data.frame</span>(<span class="pl-v">word</span><span class="pl-k">=</span>names(<span class="pl-smi">freq</span>), <span class="pl-v">freq</span><span class="pl-k">=</span><span class="pl-smi">freq</span>)  

<span class="pl-c">#Make a bar graph of the words appearing more than 6000 times</span>
library(<span class="pl-smi">ggplot2</span>)   
<span class="pl-v">p</span> <span class="pl-k">=</span> ggplot(subset(<span class="pl-smi">wf</span>, <span class="pl-smi">freq</span><span class="pl-k">&gt;</span><span class="pl-c1">6000</span>), aes(<span class="pl-smi">word</span>, <span class="pl-smi">freq</span>))    
<span class="pl-v">p</span> <span class="pl-k">=</span> <span class="pl-smi">p</span> <span class="pl-k">+</span> geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>)   
<span class="pl-v">p</span> <span class="pl-k">=</span> <span class="pl-smi">p</span> <span class="pl-k">+</span> theme(<span class="pl-v">axis.text.x</span><span class="pl-k">=</span>element_text(<span class="pl-v">angle</span><span class="pl-k">=</span><span class="pl-c1">45</span>, <span class="pl-v">hjust</span><span class="pl-k">=</span><span class="pl-c1">1</span>))   
<span class="pl-smi">p</span>   </pre></div>

<p><img src="http://i.imgur.com/QaADvIn.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#Create a word cloud of the 60 most frequently occuring words</span>
library(<span class="pl-smi">wordcloud</span>)   
set.seed(<span class="pl-c1">145</span>)   
wordcloud(names(<span class="pl-smi">freq</span>), <span class="pl-smi">freq</span>, <span class="pl-v">max.words</span> <span class="pl-k">=</span> <span class="pl-c1">60</span>, <span class="pl-v">scale</span><span class="pl-k">=</span>c(<span class="pl-c1">5</span>, .<span class="pl-c1">1</span>), <span class="pl-v">colors</span><span class="pl-k">=</span>brewer.pal(<span class="pl-c1">6</span>, <span class="pl-s"><span class="pl-pds">"</span>Dark2<span class="pl-pds">"</span></span>))</pre></div>

<p><img src="http://i.imgur.com/jp97IGK.png" alt=""></p>

<p>Once the exploratory data analysis was complete, it was decided to separate the data set based on 4 topics: Customer Service (CS), Bank Services (S), Public Relations (PR), and Nonsense (NS). </p>

<p><strong>Example list of frequent words later used to manually define posts into the Bank Services category:</strong></p>

<table>
<thead>
<tr>
<th><strong>account</strong></th>
<th><strong>card</strong></th>
<th><strong>money</strong></th>
<th><strong>email</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>rate</strong></td>
<td><strong>check</strong></td>
<td><strong>credit</strong></td>
<td><strong>cash</strong></td>
</tr>
<tr>
<td><strong>pay</strong></td>
<td><strong>buy</strong></td>
<td><strong>loan</strong></td>
<td><strong>atm</strong></td>
</tr>
<tr>
<td><strong>deposit</strong></td>
<td><strong>fee</strong></td>
<td><strong>online</strong></td>
<td><strong>debit</strong></td>
</tr>
</tbody>
</table>

<p><strong>Creation of sentiment analysis function</strong></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#This function counts the number of positive words and negative words in a post</span>
<span class="pl-c">#Positive and Negative words are imported from text files named positive-words.txt and negative-words.txt</span>
<span class="pl-c">#The difference is the sentiment score</span>
<span class="pl-c">#The difference divided by the number of words in the FullTextClean column is the sentiment density</span>
<span class="pl-c">#This normalizes sentiment scores between very short posts (tweets) and very long posts (on facebook)</span>
<span class="pl-v">sentimentAnalysis</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">df</span>)
{
  <span class="pl-smi">pos</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>positive-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)
  <span class="pl-smi">neg</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>negative-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)
  require(<span class="pl-smi">plyr</span>)
  require(<span class="pl-smi">stringr</span>)

  <span class="pl-v">scores</span> <span class="pl-k">=</span> laply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullTextClean</span>, <span class="pl-k">function</span>(<span class="pl-smi">sentence</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>) {
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">sentence</span>)
    <span class="pl-v">word.list</span> <span class="pl-k">=</span> str_split(<span class="pl-smi">sentence</span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>s+<span class="pl-pds">'</span></span>)
    <span class="pl-v">words</span> <span class="pl-k">=</span> unlist(<span class="pl-smi">word.list</span>)
    <span class="pl-v">words.length</span> <span class="pl-k">=</span> length(<span class="pl-smi">words</span>)

    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">pos.words</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">neg.words</span>)

    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">pos.matches</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">neg.matches</span>)

    <span class="pl-v">score</span> <span class="pl-k">=</span> sum(<span class="pl-smi">pos.matches</span>) <span class="pl-k">-</span> sum(<span class="pl-smi">neg.matches</span>)
    <span class="pl-k">if</span>(<span class="pl-smi">words.length</span> <span class="pl-k">==</span> <span class="pl-c1">0</span>) <span class="pl-v">score.density</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
    <span class="pl-k">else</span> <span class="pl-v">score.density</span> <span class="pl-k">=</span> <span class="pl-smi">score</span><span class="pl-k">/</span><span class="pl-smi">words.length</span>
    <span class="pl-v">score.list</span> <span class="pl-k">=</span> c(<span class="pl-smi">score</span>, <span class="pl-smi">score.density</span>)

    <span class="pl-k">return</span>(<span class="pl-smi">score.list</span>)
  }, <span class="pl-smi">pos</span>, <span class="pl-smi">neg</span>, <span class="pl-v">.progress</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>text<span class="pl-pds">'</span></span>)

  <span class="pl-v">scores.df</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">SentimentScore</span><span class="pl-k">=</span><span class="pl-smi">scores</span>[,<span class="pl-c1">1</span>], <span class="pl-v">SentimentDensity</span><span class="pl-k">=</span><span class="pl-smi">scores</span>[,<span class="pl-c1">2</span>])
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">SentimentScore</span> <span class="pl-k">=</span> <span class="pl-smi">scores</span>[,<span class="pl-c1">1</span>]
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">SentimentDensity</span> <span class="pl-k">=</span> <span class="pl-smi">scores</span>[,<span class="pl-c1">2</span>]
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">very.pos</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">SentimentScore</span> <span class="pl-k">&gt;</span><span class="pl-k">=</span> <span class="pl-c1">2</span>)
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">very.neg</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">SentimentDensity</span> <span class="pl-k">&lt;</span><span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2</span>)
  <span class="pl-k">return</span>(<span class="pl-smi">df</span>)
}</pre></div>

<h3>
<a id="bag-of-words-random-forest-classification-algorithm" class="anchor" href="#bag-of-words-random-forest-classification-algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bag-of-Words Random Forest Classification Algorithm</h3>

<p>In order to classify the data set into the constructed categories (Customer Service, Bank Services, Public Relations, and Nonsense) using a bag-of-words random forest classification algorithm, a sample of 600 posts were labeled by category and continuously applied to the dataset. For example, if a post mentions “atm” or “online banking,” it would be labeled in the Bank Services category. </p>

<p>The program then learned from the sample data to create predictions of category for each post. During cross validation, the accuracy of predictions was found to be approximately 77%. The classification tree and naive bayes classification algorithms were also tested, but both had much lower accuracy. A larger training data set (&gt;600 posts)would likely improve accuracy further.</p>

<p><img src="http://i.imgur.com/8u5rA0g.png" alt=""></p>

<h3>
<a id="overall-sentiment" class="anchor" href="#overall-sentiment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overall Sentiment</h3>

<p><em>Boxplot of Sentiment Density Scores for each Topic. Nonsense posts made up the majority of all posts and have the greatest spread of sentiment.</em>
<img src="http://i.imgur.com/cXxmn7v.png" alt=""></p>

<p><em>Average Sentiment Density Scores for each Topic. The nonsense posts provide a baseline sentiment score against which we can compare the other topics. Across all posts, scores for bank services average negative and scores for customer service and public relations average positive.</em>
<img src="http://i.imgur.com/Qp9dhJp.png" alt=""></p>

<p>On average, customers have positive sentiments for customer service related posts and negative sentiments for bank services related posts. Therefore, the substance for both customer service and bank services is universal across the industry. However, the degree of sentiment associated with each category varies by bank. While customers have generally negative interactions with banking services, banks appear to be able to compensate for these issues with generally positive interactions with public relations and customer service. Banks should focus on improving their Bank Services as listed above.</p>

<h3>
<a id="separating-the-posts-by-bank" class="anchor" href="#separating-the-posts-by-bank" aria-hidden="true"><span class="octicon octicon-link"></span></a>Separating the Posts by Bank</h3>

<div class="highlight highlight-source-r"><pre><span class="pl-c">#This function analyzes the dataset to identify which banks are mentioned in each post.</span>
<span class="pl-c">#It creates 5 new variables (for banks A-E)</span>
<span class="pl-c">#The field has a 0 if the bank is not mentioned, and a 1 if the bank is mentioned.</span>
<span class="pl-c">#It also creates a field that counts the number of banks mentioned in the post.</span>
<span class="pl-c">#Some posts mention 0 banks, most mention 1, and a few mention multiple</span>
<span class="pl-v">bankMentions</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">df</span>)
{
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">BankA</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">BankB</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">BankC</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">BankD</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">BankE</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">NumBanks</span> <span class="pl-k">=</span> <span class="pl-c1">0</span>
  <span class="pl-k">for</span>( <span class="pl-smi">i</span> <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nrow(<span class="pl-smi">df</span>))
  {
    <span class="pl-k">if</span> (grepl(<span class="pl-s"><span class="pl-pds">"</span>BankA<span class="pl-pds">"</span></span>,<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>[<span class="pl-smi">i</span>]))  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankA</span>[<span class="pl-smi">i</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span>
    <span class="pl-k">if</span> (grepl(<span class="pl-s"><span class="pl-pds">"</span>BankB<span class="pl-pds">"</span></span>,<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>[<span class="pl-smi">i</span>]))  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankB</span>[<span class="pl-smi">i</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span>
    <span class="pl-k">if</span> (grepl(<span class="pl-s"><span class="pl-pds">"</span>BankC<span class="pl-pds">"</span></span>,<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>[<span class="pl-smi">i</span>]))  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankC</span>[<span class="pl-smi">i</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span>
    <span class="pl-k">if</span> (grepl(<span class="pl-s"><span class="pl-pds">"</span>BankD<span class="pl-pds">"</span></span>,<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>[<span class="pl-smi">i</span>]))  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankD</span>[<span class="pl-smi">i</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span>
    <span class="pl-k">if</span> (grepl(<span class="pl-s"><span class="pl-pds">"</span>banke<span class="pl-pds">"</span></span>,<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>[<span class="pl-smi">i</span>]))  <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankE</span>[<span class="pl-smi">i</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span>
    <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">NumBanks</span>[<span class="pl-smi">i</span>] <span class="pl-k">=</span> <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankA</span>[<span class="pl-smi">i</span>] <span class="pl-k">+</span> <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankB</span>[<span class="pl-smi">i</span>] <span class="pl-k">+</span> <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankC</span>[<span class="pl-smi">i</span>] <span class="pl-k">+</span> <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankD</span>[<span class="pl-smi">i</span>] <span class="pl-k">+</span> <span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankE</span>[<span class="pl-smi">i</span>]
  }

  <span class="pl-k">return</span>(<span class="pl-smi">df</span>)
}</pre></div>

<p><img src="http://i.imgur.com/8J6V5FE.png" alt=""></p>

<p><em>Average Sentiment Density Scores by Topic and Bank</em></p>

<p><img src="http://i.imgur.com/CZ8JX5d.png" alt=""></p>

<p>Sentiment scores varied in magnitude and direction by bank for each topic. For example, Bank B had the most positive sentiments for customer service and pr, but the most negative sentiment for bank services. It is possible that Bank B is forced to compensate for poor banking services with more customer service and public relations. This information is useful for individual banks to see how their services compare to their competitors. </p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/daniellejschwartz/Wells-Fargo-Analytic-Competition-2015">Wells Fargo Analytics Competition 2015</a> is maintained by <a href="https://github.com/daniellejschwartz">daniellejschwartz</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
